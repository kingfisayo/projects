#Text Mining- SRAM 818 Project - Employees' Reviews scraped fromm Glassdoor 
library("rJava")
library("qdap")
library("dplyr") 
library("tm") 
library("wordcloud") 
library("plotrix") 
library("dendextend") 
library("ggplot2") 
library("ggthemes") 
library("RWeka") 

#Set Working Directory
setwd("C:/Users/fisay/Desktop/Desktop 2/QUALITATIVE DATA ANALYSIS-PROJECT SRAM 818/Datasets3")
getwd()

#Import Datasets
jpm3<-read.csv("jpm3.csv", stringsAsFactors = FALSE)
boa3<-read.csv("boa3.csv", stringsAsFactors = FALSE)

jpm3<-jpm3[(1:4500),]
boa3<-boa3[(1:4500),]
#Check the Structure of Datasets
str(jpm3)
str(boa3)

#Create Pros and cons vectors
jpm3pros<-jpm3$rev.pros
jpm3cons<-jpm3$rev.cons
boa3pros<-boa3$rev.pros
boa3cons<-boa3$rev.cons

#Text cleaning and organization function
qdap_clean <- function(x) {   
  x <- replace_abbreviation(x)   
  x <- replace_contraction(x)   
  x <- replace_number(x)   
  x <- replace_ordinal(x)   
  x <- replace_symbol(x)   
  x <- tolower(x)   
  return(x) 
} 

#Clean with tm 
tm_clean <- function(corpus) {   
  corpus <- tm_map(corpus, removePunctuation)   
  corpus <- tm_map(corpus, stripWhitespace)   
  corpus <- tm_map(corpus, removeWords,                     
                   c(stopwords("en"), "bank of america", "can", "will make", "wells fargo" , "four hundred", "na na", "one hundred" , "onek", "jp morgan", "chase", "company"))   
  return(corpus) 
}
#Clean the pros and cons vectors with qdap
jpm3pros<-qdap_clean(jpm3pros)
jpm3cons<-qdap_clean(jpm3cons)
boa3pros<-qdap_clean(boa3pros)
boa3cons<-qdap_clean(boa3cons)

#Remove NAs so before creating corpus so RWeka tokenizer can work
jpm3pros[which(is.na(jpm3pros))] <- "NULL" 
jpm3cons[which(is.na(jpm3cons))] <- "NULL"
boa3pros[which(is.na(boa3pros))] <- "NULL" 
boa3cons[which(is.na(boa3cons))] <- "NULL"

#Create Corpus
jpm3pros_corpus <- VCorpus(VectorSource(jpm3pros)) 
jpm3cons_corpus <- VCorpus(VectorSource(jpm3cons))
boa3pros_corpus <- VCorpus(VectorSource(boa3pros)) 
boa3cons_corpus <- VCorpus(VectorSource(boa3cons))

#Clean the corpus with tm
jpm3_pros_corp <- tm_clean(jpm3pros_corpus) 
jpm3_cons_corp <- tm_clean(jpm3cons_corpus)
boa3_pros_corp <- tm_clean(boa3pros_corpus)
boa3_cons_corp <- tm_clean(boa3cons_corpus)

#Create a tokenizer function
tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))

#Create corpus tdm
jpm3_pros_tdm <- TermDocumentMatrix(   
  jpm3_pros_corp,    
  control = list(tokenize = tokenizer)   
)
jpm3_cons_tdm <- TermDocumentMatrix(   
  jpm3_cons_corp,    
  control = list(tokenize = tokenizer)   
)
boa3_pros_tdm <- TermDocumentMatrix(   
  boa3_pros_corp,    
  control = list(tokenize = tokenizer)   
)
boa3_cons_tdm <- TermDocumentMatrix(   
  boa3_cons_corp,    
  control = list(tokenize = tokenizer)   
)

#Create Matrix from corpus tdm
jpm3_pros_tdm_m <- as.matrix(jpm3_pros_tdm) 
jpm3_cons_tdm_m <- as.matrix(jpm3_cons_tdm) 
boa3_pros_tdm_m <- as.matrix(boa3_pros_tdm)
boa3_cons_tdm_m <- as.matrix(boa3_cons_tdm)

#Create their frequencies
jpm3_pros_freq <- rowSums(jpm3_pros_tdm_m)
jpm3_cons_freq <- rowSums(jpm3_cons_tdm_m)
boa3_pros_freq <- rowSums(boa3_pros_tdm_m)
boa3_cons_freq <- rowSums(boa3_cons_tdm_m)

#Plot a Word Cloud using the frequencies
#Jpm3 Pros
wordcloud(names(jpm3_pros_freq),   
          jpm3_pros_freq,   
          max.words = 25,    
          color = "blue") 
#Jpm3 Cons
wordcloud(names(jpm3_cons_freq),   
          jpm3_cons_freq,   
          max.words = 25,    
          color = "red") 
#Boa3 Pros
wordcloud(names(boa3_pros_freq),   
          boa3_pros_freq,   
          max.words = 25,    
          color = "blue") 
#Boa3 Cons
wordcloud(names(boa3_cons_freq),   
          boa3_cons_freq,   
          max.words = 20,    
          color = "red") 

#Jpm3 Pros Dendogram
jpm3_pros_tdm <- TermDocumentMatrix( 
  jpm3_pros_corp,  
  control = list(tokenize = tokenizer))
# Print amzn_c_tdm to the console 
jpm3_pros_tdm 
##<<TermDocumentMatrix (terms: 4778, documents: 500)>> 
##Non-/sparse entries: 5220/2383780 
##Sparsity           : 100% 
##Maximal term length: 31 
##Weighting          : term frequency (tf) 
# Create amzn_c_tdm2 by removing sparse terms  
jpm3_pros_tdm2 <- removeSparseTerms(jpm3_pros_tdm, sparse = .993) 

# Create hc as a cluster of distance values 
hc <- hclust( 
  d = dist(jpm3_pros_tdm2, method = "euclidean"),  
  method = "complete") 

# Produce a plot of hc 
plot(hc) 

#Jpm3 Cons Dendogram
jpm3_cons_tdm <- TermDocumentMatrix( 
  jpm3_cons_corp,  
  control = list(tokenize = tokenizer))
# Print jpm3_cons_tdm to the console 
jpm3_cons_tdm 
##<<TermDocumentMatrix (terms: 4778, documents: 500)>> 
##Non-/sparse entries: 5220/2383780 
##Sparsity           : 100% 
##Maximal term length: 31 
##Weighting          : term frequency (tf) 
# Create amzn_c_tdm2 by removing sparse terms  
jpm3_cons_tdm2 <- removeSparseTerms(jpm3_cons_tdm, sparse = .993) 

# Create hc as a cluster of distance values 
hc2 <- hclust( 
  d = dist(jpm3_cons_tdm2, method = "euclidean"),  
  method = "complete") 

# Produce a plot of hc 
plot(hc2) 

#Boa3 Pros Dendogram
boa3_pros_tdm <- TermDocumentMatrix( 
  boa3_pros_corp,  
  control = list(tokenize = tokenizer))
# Print boa3_pros_tdm to the console 
boa3_pros_tdm 
##<<TermDocumentMatrix (terms: 4778, documents: 500)>> 
##Non-/sparse entries: 5220/2383780 
##Sparsity           : 100% 
##Maximal term length: 31 
##Weighting          : term frequency (tf) 
# Create amzn_c_tdm2 by removing sparse terms  
boa3_pros_tdm2 <- removeSparseTerms(boa3_pros_tdm, sparse = .993) 

# Create hc as a cluster of distance values 
hc3 <- hclust( 
  d = dist(boa3_pros_tdm2, method = "euclidean"),  
  method = "complete") 

# Produce a plot of hc 
plot(hc3) 

#Boa3 Cons Dendogram
boa3_cons_tdm <- TermDocumentMatrix( 
  boa3_cons_corp,  
  control = list(tokenize = tokenizer))
# Print boa3_cons_tdm to the console 
boa3_cons_tdm 
##<<TermDocumentMatrix (terms: 4778, documents: 500)>> 
##Non-/sparse entries: 5220/2383780 
##Sparsity           : 100% 
##Maximal term length: 31 
##Weighting          : term frequency (tf) 
# Create amzn_c_tdm2 by removing sparse terms  
boa3_cons_tdm2 <- removeSparseTerms(boa3_cons_tdm, sparse = .993) 

# Create hc as a cluster of distance values 
hc4 <- hclust( 
  d = dist(boa3_cons_tdm2, method = "euclidean"),  
  method = "complete") 

# Produce a plot of hc 
plot(hc4) 

#Word Associations
#Jpm3 Pros
# Create jpm3_pros_tdm 
jpm3_pros_tdm <- TermDocumentMatrix( 
  jpm3_pros_corp, 
  control = list(tokenize = tokenizer) 
) 
# Create jpm3_pros_m 
jpm3_pros_m <- as.matrix(jpm3_pros_tdm) 
# Create jpm3_pros_freq 
jpm3_pros_freq <- rowSums(jpm3_pros_m) 
# Create term_frequency 
jpm3pros_term_frequency <- sort(jpm3_pros_freq, decreasing = T) 
# Print the 10 most common terms 
jpm3pros_term_frequency[1:10] 
jpm3pros_mostoccuringterms<-as.data.frame(jpm3pros_term_frequency[1:10])

#Jpm3 Cons
# Create jpm3_cons_tdm 
jpm3_cons_tdm <- TermDocumentMatrix( 
  jpm3_cons_corp, 
  control = list(tokenize = tokenizer) 
) 
# Create jpm3_cons_m 
jpm3_cons_m <- as.matrix(jpm3_cons_tdm) 
# Create jpm3_cons_freq 
jpm3_cons_freq <- rowSums(jpm3_cons_m) 
# Create term_frequency 
jpm3consterm_frequency <- sort(jpm3_cons_freq, decreasing = T) 
# Print the 10 most common terms 
jpm3consterm_frequency[1:10] 
jpm3cons_mostoccuringterms<-as.data.frame(jpm3consterm_frequency[1:10])

#Boa3 Pros
# Create boa3_pros_tdm 
boa3_pros_tdm <- TermDocumentMatrix( 
  boa3_pros_corp, 
  control = list(tokenize = tokenizer) 
) 
# Create boa3_pros_m 
boa3_pros_m <- as.matrix(boa3_pros_tdm) 
# Create boa3_pros_freq 
boa3_pros_freq <- rowSums(boa3_pros_m) 
# Create term_frequency 
boa3_pros_term_frequency <- sort(boa3_pros_freq, decreasing = T) 
# Print the 10 most common terms 
boa3_pros_term_frequency[1:10] 
boa3_pros_mostoccuringterms<-as.data.frame(boa3_pros_term_frequency[1:10])

#Boa3 Cons
# Create boa3_cons_tdm 
boa3_cons_tdm <- TermDocumentMatrix( 
  boa3_cons_corp, 
  control = list(tokenize = tokenizer) 
) 
# Create boa3_pros_m 
boa3_cons_m <- as.matrix(boa3_cons_tdm) 
# Create boa3_pros_freq 
boa3_cons_freq <- rowSums(boa3_cons_m) 
# Create term_frequency 
boa3_cons_term_frequency <- sort(boa3_cons_freq, decreasing = T) 
# Print the 10 most common terms 
boa3_cons_term_frequency[1:10] 
boa3_cons_mostoccuringterms<-as.data.frame(boa3_cons_term_frequency[1:10])

# Find associations with good benefits
jpm3prosassociations_work_life <- findAssocs(jpm3_pros_tdm, "work life", 0.2) 
head(jpm3prosassociations_work_life$`work life`, 20)
jpm3prosassociations_work_life_word_associations<-as.data.frame(head(jpm3prosassociations_good_benefits$`good benefits`, 20))
# Find associations with demanding lot
jpm3consassociations_demanding_lot <- findAssocs(jpm3_cons_tdm, "demanding lot", 0.2) 
head(jpm3consassociations_demanding_lot$`demanding lot`, 20)
jpm3consassociations_demanding_lot_word_associations<-as.data.frame(head(jpm3consassociations_demanding_lot$`demanding lot`, 20))

# Find associations with support everyone
boa3_prosassociations_support_everyone <- findAssocs(boa3_pros_tdm, "support everyone", 0.2) 
head(boa3_prosassociations_support_everyone$`support everyone`, 20)
boa3_prosassociations_support_everyone_word_associations<-as.data.frame(head(boa3_prosassociations_support_everyone$`support everyone`, 20))

# Find associations with amount work
boa3_consassociations_amount_work <- findAssocs(boa3_cons_tdm, "amount work", 0.2) 
head(boa3_consassociations_amount_work$`amount work`, 20)
boa3_consassociations_amount_work_word_associations<-as.data.frame(head(boa3_consassociations_amount_work$`amount work`, 20))

#Export results
write.csv(jpm3pros_mostoccuringterms, "C:/Users/fisay/Desktop/Desktop 2/QUALITATIVE DATA ANALYSIS-PROJECT SRAM 818/Results3/jpm3_pros_mostoccuringterms.csv")
write.csv(jpm3cons_mostoccuringterms, "C:/Users/fisay/Desktop/Desktop 2/QUALITATIVE DATA ANALYSIS-PROJECT SRAM 818/Results3/jpm3_cons_mostoccuringterms.csv")
write.csv(boa3_cons_mostoccuringterms, "C:/Users/fisay/Desktop/Desktop 2/QUALITATIVE DATA ANALYSIS-PROJECT SRAM 818/Results3/boa3_cons_mostoccuringterms.csv")
write.csv(boa3_pros_mostoccuringterms, "C:/Users/fisay/Desktop/Desktop 2/QUALITATIVE DATA ANALYSIS-PROJECT SRAM 818/Results3/boa3_pros_mostoccuringterms.csv")

#Pros with Cons together WordCloud

#jpm3 Pros&Cons Comparison
#Create the Corpus
all_jpm3_corpus <- VCorpus(VectorSource(jpm3[,6:7]))
#Clean the Corpus
all_jpm3_corp <- tm_clean(all_jpm3_corpus)
#Create Term Document Matrix
all_tdm_jpm3 <- TermDocumentMatrix(all_jpm3_corp)
# Name the columns of all_tdm_jpm3
colnames(all_tdm_jpm3) <- c("JPMorgan_Pros", "JPMorgan_Cons")
# Create as Matrix
all_m_jpm3 <- as.matrix(all_tdm_jpm3)
head(all_m_jpm3)
#Build a Comparison Cloud
comparison.cloud(all_m_jpm3,
                 colors = c("#F44336", "#2196f3"),
                 max.words = 100)

#Boa3 Pros&Cons Comparison
#Create the Corpus
all_boa3_corpus <- VCorpus(VectorSource(boa3[,6:7]))
#Clean the Corpus
all_boa3_corp <- tm_clean(all_boa3_corpus)
#Create Term Document Matrix
all_tdm_boa3 <- TermDocumentMatrix(all_boa3_corp)
# Name the columns of all_tdm_jpm3
colnames(all_tdm_boa3) <- c("BoA_Pros", "BoA_Cons")
# Create as Matrix
all_m_boa3 <- as.matrix(all_tdm_boa3)
head(all_m_boa3)
#Build a Comparison Cloud
comparison.cloud(all_m_boa3,
                 colors = c("#F44336", "#2196f3"),
                 max.words = 100)

#Cage Batch
#Jpm3 VS boa3 pro reviews
# create a data frame of just the positive reviews
pros <- data.frame(jpm3_pros = as.character(jpm3$rev.pros),
                   boa3_pros = as.character(boa3$rev.pros),
                   stringsAsFactors = F)
#Clean with qdap
pros[is.na(pros)] <- "NULL"
pros <- qdap_clean(pros)

# Create a corpus
all_pros_corp <- VCorpus(VectorSource(pros))
all_pros_corp <- tm_clean(all_pros_corp)

#Create a tokenizer function
tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))

# Create a tdm with bi-grams
all_tdm <- TermDocumentMatrix(
  all_pros_corp,
  control = list(tokenize = tokenizer)
)

# Create pro_p_m
all_tdm_m <- as.matrix(all_tdm)

head(all_tdm_m)

# Create common_words
common_words <- subset(all_tdm_m, 
                       all_tdm_m[, 1] > 0 & all_tdm_m[, 2] > 0)


# Create difference
difference <- abs(common_words[, 1] - common_words[, 2])

# Add difference to common_words
common_words <- cbind(common_words, difference)

# Order the data frame from most differences to least
common_words <- common_words[order(common_words[,3], decreasing = T), ]

# Create top8_df
top15_df <- data.frame(
  x = common_words[1:30, 1],
  y = common_words[1:30, 2],
  labels = rownames(common_words[1:30, ])
)

# Create the pyramid plot
pyramid.plot(top15_df$x, top15_df$y, 
             labels = top15_df$labels, 
             gap = 300, 
             top.labels = c("JPMorgan", "Pro Words", "BankofAmerica"), 
             main = "Words in Common", unit = NULL)

library("stringi")
library("stringr")


jpm3pros<-str_to_lower(jpm3pros)
boa3pros<-str_to_lower(boa3pros)
#Pay&Benefits
Pay_Benefits1<-sum(str_count(jpm3pros,"salary|benefit|pay|paid|benifit"))
Pay_Benefits2<-sum(str_count(boa3pros,"salary|benefit|pay|paid|benifit"))
#Work-Life Balance
WorkLife_Balance1<-sum(str_count(jpm3pros,"life|work"))
WorkLife_Balance2<-sum(str_count(boa3pros,"life|work"))
#Management
Management1<-sum(str_count(jpm3pros,"management"))
Management2<-sum(str_count(boa3pros,"management"))
#Work Environment
Work_Environment1<-sum(str_count(jpm3pros,"support|environment|culture|place|responsibility|corporate|people"))
Work_Environment2<-sum(str_count(boa3pros,"support|environment|culture|place|responsibility|corporate|people"))

a<-rbind(Pay_Benefits1,WorkLife_Balance1,Management1,Work_Environment1)
b<-rbind(Pay_Benefits2,WorkLife_Balance2,Management2,Work_Environment2)
c<-cbind(a,b)
c<-as.data.frame(c)
row.names(c)<-c("Pay&Benefits","Work-Life Balance","Management","Work Environment")

# Create the pyramid plot Pros
pyramid.plot(c$V1, c$V2, 
             labels = row.names(c), 
             gap = 1000, 
             top.labels = c("JP Morgan Chase Bank", "Pros" , "Bank of America"), 
             main = "JP Morgan Chase Bank Vs Bank of America (Pros)", unit = NULL)

#Jpm3 VS Boa3 Cons reviews
# create a data frame of just the negative reviews
cons <- data.frame(jpm3_cons = as.character(jpm3$rev.cons),
                   boa3_cons = as.character(boa3$rev.cons),
                   stringsAsFactors = F)
#Clean with qdap
cons[is.na(cons)] <- "NULL"
cons <- qdap_clean(cons)

# Create a corpus
all_cons_corp <- VCorpus(VectorSource(cons))
all_cons_corp <- tm_clean(all_cons_corp)

#Create a tokenizer function
tokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))

# Create a tdm with bi-grams
all_tdm1 <- TermDocumentMatrix(
  all_cons_corp,
  control = list(tokenize = tokenizer)
)

# Create con_p_m
all_tdm_m1 <- as.matrix(all_tdm1)

head(all_tdm_m1)

# Create common_words
common_words1 <- subset(all_tdm_m1, 
                       all_tdm_m1[, 1] > 0 & all_tdm_m1[, 2] > 0)


# Create difference
difference1 <- abs(common_words1[, 1] - common_words1[, 2])

# Add difference to common_words
common_words1 <- cbind(common_words1, difference1)

# Order the data frame from most differences to least
common_words1 <- common_words1[order(common_words1[,3], decreasing = T), ]

# Create top8_df
top15_df1 <- data.frame(
  x = common_words1[1:30, 1],
  y = common_words1[1:30, 2],
  labels = rownames(common_words1[1:30, ])
)

# Create the pyramid plot
pyramid.plot(top15_df1$x, top15_df1$y, 
             labels = top15_df1$labels, 
             gap = 130, 
             top.labels = c("JPMorgan", "Con Words", "BankofAmerica"), 
             main = "Words in Common", unit = NULL)

library("stringi")
library("stringr")

jpm_p<-str_to_lower(jpm3$rev.pros)
boa_p<-str_to_lower(boa3$rev.pros)
jpm_c<-str_to_lower(jpm3$rev.cons)
boa_c<-str_to_lower(boa3$rev.cons)

#Theme Analysis (Pay, Management, Work-life Balance, Senior Management,
#Middle Management, Micro Management, Benefits)
Pay1<-sum(str_count(jpm_p, "pay|salary|paid|wage"))
Pay2<-sum(str_count(boa_p, "pay|salary|paid|wage"))
Pay3<-sum(str_count(jpm_c, "pay|salary|paid|wage"))
Pay4<-sum(str_count(boa_c, "pay|salary|paid|wage"))
Management1<-sum(str_count(jpm_p, "manage"))
Management2<-sum(str_count(boa_p, "manage"))
Management3<-sum(str_count(jpm_c, "manage"))
Management4<-sum(str_count(boa_c, "manage"))
Work_LifeBalance1<-sum(str_count(jpm_p, "work life|life balance|hour|work balance"))
Work_LifeBalance2<-sum(str_count(boa_p, "work life|life balance|hour|work balance"))
Work_LifeBalance3<-sum(str_count(jpm_c, "work life|life balance|hour|work balance"))
Work_LifeBalance4<-sum(str_count(boa_c, "work life|life balance|hour|work balance"))
Senior_Management1<-sum(str_count(jpm_p, "senior manage|upper manage"))
Senior_Management2<-sum(str_count(boa_p, "senior manage|upper manage"))
Senior_Management3<-sum(str_count(jpm_c, "senior manage|upper manage"))
Senior_Management4<-sum(str_count(boa_c, "senior manage|upper manage"))
Middle_Management1<-sum(str_count(jpm_p, "middle manage"))
Middle_Management2<-sum(str_count(boa_p, "middle manage"))
Middle_Management3<-sum(str_count(jpm_c, "middle manage"))
Middle_Management4<-sum(str_count(boa_c, "middle manage"))
Lower_Management1<-sum(str_count(jpm_p, "lower manage"))
Lower_Management2<-sum(str_count(boa_p, "lower manage"))
Lower_Management3<-sum(str_count(jpm_c, "lower manage"))
Lower_Management4<-sum(str_count(boa_c, "lower manage"))
Micro_Management1<-sum(str_count(jpm_p, "micro manage"))
Micro_Management2<-sum(str_count(boa_p, "micro manage"))
Micro_Management3<-sum(str_count(jpm_c, "micro manage"))
Micro_Management4<-sum(str_count(boa_c, "micro manage"))
Macro_Management1<-sum(str_count(jpm_p, "macro manage"))
Macro_Management2<-sum(str_count(boa_p, "macro manage"))
Macro_Management3<-sum(str_count(jpm_c, "macro manage"))
Macro_Management4<-sum(str_count(boa_c, "macro manage"))

Benefits1<-sum(str_count(jpm_p, "benefit"))
Benefits2<-sum(str_count(boa_p, "benefit"))
Benefits3<-sum(str_count(jpm_c, "benefit"))
Benefits4<-sum(str_count(boa_c, "benefit"))




a<-rbind(Pay1,Work_LifeBalance1,Management1,Benefits1)
b<-rbind(Pay2,Work_LifeBalance2,Management2,Benefits2)
c<-cbind(a,b)
c<-as.data.frame(c)
row.names(c)<-c("Pay","WorkLifeBalance","Management","Benefits")
?barplot(C)
# Create the pyramid plot Pros
pyramid.plot(c$V1, c$V2, 
             labels = row.names(c), 
             gap = 440, 
             top.labels = c("JPMorganChase", "Pros" , "BankofAmerica"), 
             main = "JP Morgan Chase Bank Vs Bank of America (Pros)", unit = NULL)

d<-rbind(Pay3,Work_LifeBalance3,Management3,Benefits3)
e<-rbind(Pay3,Work_LifeBalance4,Management4,Benefits4)
f<-cbind(d,e)
f<-as.data.frame(f)
row.names(f)<-f("Pay","Work-Life Balance","Management","Benefits")

# Create the pyramid plot Pros
pyramid.plot(f$V1, f$V2, 
             labels = row.names(c), 
             gap = 330, 
             top.labels = c("JPMorganChase", "Cons" , "BankofAmerica"), 
             main = "JP Morgan Chase Bank Vs Bank of America (Cons)", unit = NULL)

g<-rbind(Pay3,Work_LifeBalance3,Management3,Benefits3)
h<-rbind(Pay3,Work_LifeBalance4,Management4,Benefits4)
i<-cbind(d,e)
i<-as.data.frame(i)
row.names(i)<-c("Pay","Work-Life Balance","Management","Benefits")

# Create the pyramid plot Pros
pyramid.plot(f$V1, f$V2, 
             labels = row.names(c), 
             gap = 330, 
             top.labels = c("JPMorganChase", "Cons" , "BankofAmerica"), 
             main = "JP Morgan Chase Bank Vs Bank of America (Cons)", unit = NULL)

o<-rbind(Senior_Management1,Middle_Management1,Lower_Management1,Micro_Management1,Macro_Management1)
p<-rbind(Senior_Management2,Middle_Management2,Lower_Management2,Micro_Management2,Macro_Management2)
r<-cbind(o,p)
r<-as.data.frame(r)
row.names(r)<-c("Senior Management","Middle Management","Lower Management","Micro Management","Macro Management")

# Create the pyramid plot Pros
pyramid.plot(r$V1, r$V2, 
             labels = row.names(r), 
             gap = 10, 
             top.labels = c("JPMorganChase", "Pros" , "BankofAmerica"), 
             main = "JP Morgan Chase Bank Vs Bank of America (Pros)", unit = NULL)


u<-rbind(Senior_Management3,Middle_Management3,Lower_Management3,Micro_Management3,Macro_Management3)
v<-rbind(Senior_Management4,Middle_Management4,Lower_Management4,Micro_Management4,Macro_Management4)
w<-cbind(u,v)
w<-as.data.frame(w)
row.names(w)<-c("Senior Management","Middle Management","Lower Management","Micro Management","Macro Management")

# Create the pyramid plot Cons
pyramid.plot(w$V1, w$V2, 
             labels = row.names(w), 
             gap = 15, 
             top.labels = c("JPMorganChase", "Cons" , "BankofAmerica"), 
             main = "JP Morgan Chase Bank Vs Bank of America (Cons)", unit = NULL)
#Count the number of words in each observation of a Variable
sum(str_count(jpm_p,"\\s+"))+sum(str_count(boa_p,"\\s+"))+sum(str_count(jpm_c,"\\s+"))+sum(str_count(boa_c,"\\s+"))

jpmpcount<-(str_count(jpm_p,"\\s+"))
mean(jpmpcount)
jpmccount<-(str_count(jpm_c,"\\s+"))
mean(jpmccount)
str(jpm_p)
